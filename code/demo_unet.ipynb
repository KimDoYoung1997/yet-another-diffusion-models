{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fc26d5c5",
      "metadata": {
        "id": "fc26d5c5"
      },
      "source": [
        "### U-net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "26e1195b",
      "metadata": {
        "id": "26e1195b",
        "outputId": "83563a3d-0bc4-4bda-e6e3-96fe83137577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=2)\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "print (\"Ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "# w = torch.tensor([0.1, 0.2, 0.3], requires_grad=True)\n",
        "# y = x * w\n",
        "# loss = y.sum()\n",
        "# loss.backward()\n",
        "# print(w.grad)\n",
        "# print(x.grad)"
      ],
      "metadata": {
        "id": "KB8mSdlCxdeB"
      },
      "id": "KB8mSdlCxdeB",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _x = torch.tensor([1.0, 2.0, 3.0], requires_grad=False)\n",
        "# w = torch.tensor([0.1, 0.2, 0.3], requires_grad=True)\n",
        "# _y = _x * w\n",
        "# _loss = _y.sum()\n",
        "# _loss.backward()\n",
        "# print(w.grad)\n",
        "# print(_x.grad)"
      ],
      "metadata": {
        "id": "5cuDnnOWzJk6"
      },
      "id": "5cuDnnOWzJk6",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "055ac644",
      "metadata": {
        "id": "055ac644"
      },
      "source": [
        "### Util codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3df146e",
      "metadata": {
        "id": "a3df146e",
        "outputId": "f280951f-cf0a-4e13-d78e-20567e958ac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "def np2torch(x_np,dtype=torch.float32,device='cpu'):\n",
        "    x_torch = torch.tensor(x_np,dtype=dtype,device=device)\n",
        "    return x_torch\n",
        "def torch2np(x_torch):\n",
        "    x_np = x_torch.detach().cpu().numpy()\n",
        "    return x_np\n",
        "class SinPositionEmbeddingsClass(nn.Module):\n",
        "    def __init__(self,dim=128,T=1000):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.T = T\n",
        "    @torch.no_grad()\n",
        "    def forward(self,steps=torch.arange(start=0,end=1000,step=1)):\n",
        "        device = steps.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = np.log(self.T) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = steps[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "print (\"Ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim=128\n",
        "T=1000\n",
        "steps = torch.arange(0,1000,step=1)\n",
        "print(steps.shape)\n",
        "half_dim = dim/2\n",
        "embeddings = np.log(T) / (half_dim - 1)\n",
        "embeddings"
      ],
      "metadata": {
        "id": "VAUr2scw_08k",
        "outputId": "0e26f74f-cd8b-4fbd-9d3a-7873a964a1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VAUr2scw_08k",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.10964690919019265)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings)\n",
        "embeddings = torch.exp(torch.arange(half_dim) * -embeddings)\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "5DFjj3krCZ5e",
        "outputId": "94b34928-1784-4e40-d9eb-cf758ea1c0f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5DFjj3krCZ5e",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10964690919019265\n",
            "tensor([1.0000e+00, 8.9615e-01, 8.0309e-01, 7.1969e-01, 6.4495e-01, 5.7797e-01,\n",
            "        5.1795e-01, 4.6416e-01, 4.1596e-01, 3.7276e-01, 3.3405e-01, 2.9936e-01,\n",
            "        2.6827e-01, 2.4041e-01, 2.1544e-01, 1.9307e-01, 1.7302e-01, 1.5505e-01,\n",
            "        1.3895e-01, 1.2452e-01, 1.1159e-01, 1.0000e-01, 8.9615e-02, 8.0309e-02,\n",
            "        7.1969e-02, 6.4495e-02, 5.7797e-02, 5.1795e-02, 4.6416e-02, 4.1596e-02,\n",
            "        3.7276e-02, 3.3405e-02, 2.9936e-02, 2.6827e-02, 2.4041e-02, 2.1544e-02,\n",
            "        1.9307e-02, 1.7302e-02, 1.5505e-02, 1.3895e-02, 1.2452e-02, 1.1159e-02,\n",
            "        1.0000e-02, 8.9615e-03, 8.0309e-03, 7.1969e-03, 6.4495e-03, 5.7797e-03,\n",
            "        5.1795e-03, 4.6416e-03, 4.1596e-03, 3.7276e-03, 3.3405e-03, 2.9936e-03,\n",
            "        2.6827e-03, 2.4041e-03, 2.1544e-03, 1.9307e-03, 1.7302e-03, 1.5505e-03,\n",
            "        1.3895e-03, 1.2452e-03, 1.1159e-03, 1.0000e-03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps[:5, None] , embeddings[:5,None]"
      ],
      "metadata": {
        "id": "Qd9IXTngDdxG",
        "outputId": "1dc1af49-a2df-4727-8b73-8728b86fe819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Qd9IXTngDdxG",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2],\n",
              "         [3],\n",
              "         [4]]),\n",
              " tensor([[1.0000],\n",
              "         [0.8962],\n",
              "         [0.8031],\n",
              "         [0.7197],\n",
              "         [0.6449]]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps[:, None].shape , embeddings[:,None].shape"
      ],
      "metadata": {
        "id": "R4l5sywlD9sp",
        "outputId": "ac03f3e6-f0b7-440f-850c-5c4604696734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "R4l5sywlD9sp",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000, 1]), torch.Size([64, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = steps[:, None] * embeddings[None, :]"
      ],
      "metadata": {
        "id": "bVa0c5ekDvQL"
      },
      "id": "bVa0c5ekDvQL",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "id": "f-gUZ360D7yG",
        "outputId": "88d0100f-901e-4cd2-962b-91a2f2d27257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f-gUZ360D7yG",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d6273f",
      "metadata": {
        "scrolled": true,
        "id": "f2d6273f",
        "outputId": "5735fcd2-ff2a-476a-f960-c37998ab0b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x:torch.Size([128, 100]),t:torch.Size([128, 64]) to out:torch.Size([128, 20])\n"
          ]
        }
      ],
      "source": [
        "class DenseBlockClass(nn.Module):\n",
        "    def __init__(self,in_dim=10,out_dim=5,pos_emb_dim=10,USE_POS_EMB=True):\n",
        "        \"\"\"\n",
        "            Initialize\n",
        "        \"\"\"\n",
        "        super(DenseBlockClass,self).__init__()\n",
        "        self.in_dim      = in_dim\n",
        "        self.out_dim     = out_dim\n",
        "        self.pos_emb_dim = pos_emb_dim\n",
        "        self.USE_POS_EMB = USE_POS_EMB\n",
        "\n",
        "        self.dense1 = nn.Linear(self.in_dim,self.out_dim)\n",
        "        self.bnorm1 = nn.BatchNorm1d(self.out_dim)\n",
        "        self.dense2 = nn.Linear(self.out_dim,self.out_dim)\n",
        "        self.bnorm2 = nn.BatchNorm1d(self.out_dim)\n",
        "        self.actv   = nn.ReLU()\n",
        "        self.pos_emb_mlp = nn.Linear(self.pos_emb_dim,self.out_dim)\n",
        "\n",
        "    def forward(self,x,t):\n",
        "        \"\"\"\n",
        "            Forward\n",
        "        \"\"\"\n",
        "        h = self.bnorm1(self.actv(self.dense1(x))) # dense -> actv -> bnrom1 [B x out_dim]\n",
        "        if self.USE_POS_EMB:\n",
        "            h = h + self.pos_emb_mlp(t) # [B x out_dim]\n",
        "        h = self.bnorm2(self.actv(self.dense2(h))) # [B x out_dim]\n",
        "        return h\n",
        "\n",
        "DenseBlock = DenseBlockClass(in_dim=100,out_dim=20,pos_emb_dim=64)\n",
        "x = torch.randn(128,100)\n",
        "t = torch.randn(128,64)\n",
        "out = DenseBlock(x=x,t=t) # forward Block\n",
        "\n",
        "print (\"x:%s,t:%s to out:%s\"%(x.shape,t.shape,out.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h06ztjooDBHo"
      },
      "id": "h06ztjooDBHo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4eeefe26",
      "metadata": {
        "id": "4eeefe26"
      },
      "source": [
        "### Dense U-Net\n",
        "<img src=\"https://github.com/sjchoi86/yet-another-diffusion-models/blob/main/img/DenseUNet.jpeg?raw=1\" width=\"500\" />\n",
        "<img src=\"https://github.com/sjchoi86/yet-another-diffusion-models/blob/main/img/Block.jpeg?raw=1\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae98adb",
      "metadata": {
        "id": "5ae98adb",
        "outputId": "9ed2d7d0-b660-44b4-e317-2c271bbdef28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "class DenseUNetClass(nn.Module):\n",
        "    def __init__(self,name='dense_unet',\n",
        "                 x_dim=300,pos_emb_dim=128,h_dims=[128,64],z_dim=32,\n",
        "                 USE_POS_EMB=True):\n",
        "        \"\"\"\n",
        "            Initialize\n",
        "        \"\"\"\n",
        "        super(DenseUNetClass,self).__init__()\n",
        "        self.name        = name\n",
        "        self.x_dim       = x_dim\n",
        "        self.pos_emb_dim = pos_emb_dim\n",
        "        self.h_dims      = h_dims\n",
        "        self.z_dim       = z_dim\n",
        "        self.USE_POS_EMB = True\n",
        "        # Initialize layers\n",
        "        self.init_layers()\n",
        "\n",
        "    def init_layers(self):\n",
        "        \"\"\"\n",
        "            Initialize layers\n",
        "        \"\"\"\n",
        "        self.layers = nn.ModuleDict()\n",
        "        # Encoder\n",
        "        h_prev = self.x_dim\n",
        "        for h_idx,h_dim in enumerate(self.h_dims):\n",
        "            self.layers['Enc_%02d'%(h_idx)] = DenseBlockClass(\n",
        "                in_dim=h_prev,out_dim=h_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "                USE_POS_EMB = self.USE_POS_EMB)\n",
        "            h_prev = h_dim\n",
        "        self.layers['Enc_%02d'%(len(self.h_dims))] = DenseBlockClass(\n",
        "            in_dim=self.h_dims[-1],out_dim=self.z_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "            USE_POS_EMB = self.USE_POS_EMB)\n",
        "        # Map\n",
        "        self.layers['Map'] = DenseBlockClass(\n",
        "            in_dim=self.z_dim,out_dim=self.z_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "            USE_POS_EMB = self.USE_POS_EMB)\n",
        "        # Decoder\n",
        "        h_prev = self.z_dim\n",
        "        for h_idx,h_dim in enumerate(self.h_dims[::-1]):\n",
        "            self.layers['Dec_%02d'%(h_idx)] = DenseBlockClass(\n",
        "                in_dim=h_prev,out_dim=h_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "                USE_POS_EMB = self.USE_POS_EMB)\n",
        "            h_prev = 2*h_dim\n",
        "        self.layers['Dec_%02d'%(len(self.h_dims))] = DenseBlockClass(\n",
        "            in_dim=h_prev,out_dim=self.x_dim,\n",
        "            pos_emb_dim=self.pos_emb_dim,USE_POS_EMB = self.USE_POS_EMB)\n",
        "        # Out\n",
        "        self.layers['Out'] = DenseBlockClass(\n",
        "            in_dim=2*self.x_dim,out_dim=self.x_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "            USE_POS_EMB = self.USE_POS_EMB)\n",
        "\n",
        "    def forward(self,x,t):\n",
        "        \"\"\"\n",
        "            Forward\n",
        "        \"\"\"\n",
        "        net = x # [B x x_dim]\n",
        "        # Net\n",
        "        self.nets = []\n",
        "        # Encoder\n",
        "        self.enc_paths = []\n",
        "        self.enc_paths.append(net)\n",
        "        self.nets.append(net)\n",
        "        for h_idx in range(len(self.h_dims)+1):\n",
        "            net = self.layers['Enc_%02d'%(h_idx)](net,t)\n",
        "            self.enc_paths.append(net)\n",
        "            self.nets.append(net)\n",
        "        # Map\n",
        "        net = self.layers['Map'](net,t)\n",
        "        self.nets.append(net)\n",
        "        # Decoder\n",
        "        self.dec_paths = []\n",
        "        for h_idx in range(len(self.h_dims)+1):\n",
        "            net = self.layers['Dec_%02d'%(h_idx)](net,t)\n",
        "            net = torch.cat([self.enc_paths[len(self.h_dims)-h_idx],net],dim=1)\n",
        "            self.dec_paths.append(net)\n",
        "            self.nets.append(net)\n",
        "        net = self.layers['Out'](net,t)\n",
        "        self.nets.append(net)\n",
        "        return net\n",
        "\n",
        "print (\"Ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97006e66",
      "metadata": {
        "id": "97006e66"
      },
      "source": [
        "### Demo forward path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75457c9b",
      "metadata": {
        "id": "75457c9b",
        "outputId": "41eea900-b924-411d-d87f-c2e24bb844d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready\n"
          ]
        }
      ],
      "source": [
        "DUNet = DenseUNetClass(x_dim=300,pos_emb_dim=32,h_dims=[128,64],z_dim=32,USE_POS_EMB=True)\n",
        "x = torch.randn(128,300)\n",
        "t = torch.randn(128,32)\n",
        "DUNet(x=x,t=t)\n",
        "print (\"Ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15b246c",
      "metadata": {
        "id": "a15b246c"
      },
      "source": [
        "### Print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f17986",
      "metadata": {
        "scrolled": true,
        "id": "a8f17986",
        "outputId": "b9ba44b1-f6e5-4f7a-9642-1c58ba7e5695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer information\n",
            "[0/8][ Enc_00] [300] =>[128]\n",
            "[1/8][ Enc_01] [128] =>[064]\n",
            "[2/8][ Enc_02] [064] =>[032]\n",
            "[3/8][    Map] [032] =>[032]\n",
            "[4/8][ Dec_00] [032] =>[064]\n",
            "[5/8][ Dec_01] [128] =>[128]\n",
            "[6/8][ Dec_02] [256] =>[300]\n",
            "[7/8][    Out] [600] =>[300]\n",
            "Network information\n",
            "[00/09] torch.Size([128, 300])\n",
            "[01/09] torch.Size([128, 128])\n",
            "[02/09] torch.Size([128, 64])\n",
            "[03/09] torch.Size([128, 32])\n",
            "[04/09] torch.Size([128, 32])\n",
            "[05/09] torch.Size([128, 128])\n",
            "[06/09] torch.Size([128, 256])\n",
            "[07/09] torch.Size([128, 600])\n",
            "[08/09] torch.Size([128, 300])\n"
          ]
        }
      ],
      "source": [
        "print (\"Layer information\")\n",
        "for key_idx,key in enumerate(DUNet.layers.keys()):\n",
        "    layer = DUNet.layers[key]\n",
        "    print (\"[%d/%d][%7s] [%03d] =>[%03d]\"%\n",
        "           (key_idx,len(DUNet.layers.keys()),key,layer.dense1.in_features,layer.dense1.out_features))\n",
        "\n",
        "print (\"Network information\")\n",
        "for net_idx in range(len(DUNet.nets)):\n",
        "    net = DUNet.nets[net_idx]\n",
        "    print (\"[%02d/%02d] %s\"%(net_idx,len(DUNet.nets),net.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da598878",
      "metadata": {
        "id": "da598878"
      },
      "source": [
        "### Projecting U-net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaee5648",
      "metadata": {
        "id": "aaee5648",
        "outputId": "2df30d72-5cff-45ee-8d7b-4d09bba4b550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "class SinPositionEmbeddingsClass(nn.Module):\n",
        "    def __init__(self,dim=128,T=1000):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.T = T\n",
        "    @torch.no_grad()\n",
        "    def forward(self,steps=torch.arange(start=0,end=1000,step=1)):\n",
        "        device = steps.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = np.log(self.T) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = steps[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "class DenseBlockClass(nn.Module):\n",
        "    def __init__(self,in_dim=10,out_dim=5,pos_emb_dim=10,USE_POS_EMB=True):\n",
        "        \"\"\"\n",
        "            Initialize dense block network with posisional embedding\n",
        "        \"\"\"\n",
        "        super(DenseBlockClass,self).__init__()\n",
        "        self.in_dim      = in_dim\n",
        "        self.out_dim     = out_dim\n",
        "        self.pos_emb_dim = pos_emb_dim\n",
        "        self.USE_POS_EMB = USE_POS_EMB\n",
        "        # Simple block consists of two layers\n",
        "        self.dense1 = nn.Linear(self.in_dim,self.out_dim)\n",
        "        self.bnorm1 = nn.BatchNorm1d(self.out_dim)\n",
        "        self.dense2 = nn.Linear(self.out_dim,self.out_dim)\n",
        "        self.bnorm2 = nn.BatchNorm1d(self.out_dim)\n",
        "        self.actv   = nn.ReLU()\n",
        "        # Positional embedding\n",
        "        self.pos_emb_mlp = nn.Linear(self.pos_emb_dim,self.out_dim)\n",
        "    def forward(self,x,t):\n",
        "        \"\"\"\n",
        "            Forward\n",
        "        \"\"\"\n",
        "        h = self.bnorm1(self.actv(self.dense1(x))) # dense -> actv -> bnrom1 [B x out_dim]\n",
        "        if self.USE_POS_EMB:\n",
        "            h = h + self.pos_emb_mlp(t) # [B x out_dim]\n",
        "        h = self.bnorm2(self.actv(self.dense2(h))) # [B x out_dim]\n",
        "        return h\n",
        "\n",
        "class DenoisingDenseUnetClass(nn.Module):\n",
        "    def __init__(self,\n",
        "                 name        = 'denoising_dense_unet',\n",
        "                 D           = 3,\n",
        "                 L           = 100,\n",
        "                 T           = 1000, # max diffusion steps\n",
        "                 pos_emb_dim = 127,\n",
        "                 h_dims      = [128,64],\n",
        "                 z_dim       = 32,\n",
        "                 USE_POS_EMB = True,\n",
        "                 Gammas      = None\n",
        "                ):\n",
        "        \"\"\"\n",
        "            Initialize denoising dense unet for DDPM\n",
        "            The input dimension would be L*D\n",
        "        \"\"\"\n",
        "        super(DenoisingDenseUnetClass,self).__init__()\n",
        "        self.name        = name\n",
        "        self.D           = D\n",
        "        self.L           = L\n",
        "        self.T           = T\n",
        "        self.x_dim       = self.D * self.L\n",
        "        self.pos_emb_dim = pos_emb_dim\n",
        "        self.h_dims      = h_dims\n",
        "        self.z_dim       = z_dim\n",
        "        self.USE_POS_EMB = USE_POS_EMB\n",
        "        self.Gammas      = Gammas # RKHS projections\n",
        "        # Initialize layers\n",
        "        self.init_layers()\n",
        "\n",
        "    def init_layers(self):\n",
        "        \"\"\"\n",
        "            Initialize layers\n",
        "        \"\"\"\n",
        "        self.layers = nn.ModuleDict()\n",
        "        # Encoder (x->z)\n",
        "        h_prev = self.x_dim\n",
        "        for h_idx,h_dim in enumerate(self.h_dims):\n",
        "            self.layers['Enc_%02d'%(h_idx)] = DenseBlockClass(\n",
        "                in_dim=h_prev,out_dim=h_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "                USE_POS_EMB = self.USE_POS_EMB)\n",
        "            h_prev = h_dim\n",
        "        self.layers['Enc_%02d'%(len(self.h_dims))] = DenseBlockClass(\n",
        "            in_dim=self.h_dims[-1],out_dim=self.z_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "            USE_POS_EMB = self.USE_POS_EMB)\n",
        "        # Map (z->z)\n",
        "        self.layers['Map'] = DenseBlockClass(\n",
        "            in_dim=self.z_dim,out_dim=self.z_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "            USE_POS_EMB = self.USE_POS_EMB)\n",
        "        # Decoder (z->x)\n",
        "        h_prev = self.z_dim\n",
        "        for h_idx,h_dim in enumerate(self.h_dims[::-1]):\n",
        "            self.layers['Dec_%02d'%(h_idx)] = DenseBlockClass(\n",
        "                in_dim=h_prev,out_dim=h_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "                USE_POS_EMB = self.USE_POS_EMB)\n",
        "            h_prev = 2*h_dim\n",
        "        self.layers['Dec_%02d'%(len(self.h_dims))] = DenseBlockClass(\n",
        "            in_dim=h_prev,out_dim=self.x_dim,\n",
        "            pos_emb_dim=self.pos_emb_dim,USE_POS_EMB = self.USE_POS_EMB)\n",
        "        # Out\n",
        "        self.layers['Out'] = DenseBlockClass(\n",
        "            in_dim=2*self.x_dim,out_dim=self.x_dim,pos_emb_dim=self.pos_emb_dim,\n",
        "            USE_POS_EMB = self.USE_POS_EMB)\n",
        "        # Time embedding\n",
        "        self.layers['Pos_Emb'] = nn.Sequential(\n",
        "                SinPositionEmbeddingsClass(dim=self.pos_emb_dim,T=self.T),\n",
        "                nn.Linear(self.pos_emb_dim,self.pos_emb_dim),\n",
        "                nn.GELU()\n",
        "            )\n",
        "    def forward(self,x,t):\n",
        "        \"\"\"\n",
        "            Forward\n",
        "            x: [B x x_dim]\n",
        "            t: [B x 1]\n",
        "        \"\"\"\n",
        "        net = x # [B x x_dim]\n",
        "        # Positional Embedding\n",
        "        pos_emb = self.layers['Pos_Emb'](t) # [B x pos_emb_dim]\n",
        "        # Net\n",
        "        self.nets = {}\n",
        "        # Encoder\n",
        "        self.enc_paths = []\n",
        "        self.enc_paths.append(net)\n",
        "        self.nets['x'] = net\n",
        "        for h_idx in range(len(self.h_dims)+1):\n",
        "            net = self.layers['Enc_%02d'%(h_idx)](net,pos_emb)\n",
        "            self.enc_paths.append(net)\n",
        "            self.nets['Enc_%02d'%(h_idx)] = net\n",
        "        # Map\n",
        "        net = self.layers['Map'](net,pos_emb) # [B x z_dim]\n",
        "        self.nets['Map'] = net # [B x z_dim]\n",
        "        # Decoder\n",
        "        self.dec_paths = []\n",
        "        for h_idx in range(len(self.h_dims)+1):\n",
        "            net = self.layers['Dec_%02d'%(h_idx)](net,pos_emb)\n",
        "            net = torch.cat([self.enc_paths[len(self.h_dims)-h_idx],net],dim=1)\n",
        "            self.dec_paths.append(net)\n",
        "            self.nets['Dec_%02d'%(h_idx)] = net\n",
        "        net = self.layers['Out'](net,pos_emb) # [B x LD]\n",
        "\n",
        "        # RKHS projection\n",
        "        self.Gammas # [D x L x L]\n",
        "\n",
        "\n",
        "        # Return\n",
        "        self.nets['Out'] = net  # [B x LD]\n",
        "        return net\n",
        "\n",
        "print (\"Ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad5844bd",
      "metadata": {
        "id": "ad5844bd"
      },
      "source": [
        "### Model usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a711077f",
      "metadata": {
        "id": "a711077f",
        "outputId": "9f62b2c9-35d5-45c3-dc8a-490db3754986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "from scipy.spatial import distance\n",
        "def kernel_se(x1,x2,hyp={'gain':1.0,'len':1.0}):\n",
        "    \"\"\" Squared-exponential kernel function \"\"\"\n",
        "    D = distance.cdist(x1/hyp['len'],x2/hyp['len'],'sqeuclidean')\n",
        "    K = hyp['gain']*np.exp(-D)\n",
        "    return K\n",
        "def get_gamma(times=np.linspace(start=0.0,stop=1.0,num=100).reshape((-1,1)), # [L x 1]\n",
        "              hyp_len=1.0,reg_coef=1e-8):\n",
        "    \"\"\"\n",
        "        RKHS projection\n",
        "    \"\"\"\n",
        "    L = times.shape[0]\n",
        "    K = kernel_se(times,times,hyp={'gain':1.0,'len':hyp_len}) # [L x L]\n",
        "    Gamma = K @ np.linalg.inv(K + reg_coef*np.eye(L,L)) # [L x L]\n",
        "    return Gamma\n",
        "print (\"Ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42c3f88",
      "metadata": {
        "id": "b42c3f88",
        "outputId": "c62637f4-abf3-4a41-9f90-ad46a8a932cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00] [       x]: torch.Size([5, 300])\n",
            "[01] [  Enc_00]: torch.Size([5, 64])\n",
            "[02] [  Enc_01]: torch.Size([5, 32])\n",
            "[03] [     Map]: torch.Size([5, 32])\n",
            "[04] [  Dec_00]: torch.Size([5, 128])\n",
            "[05] [  Dec_01]: torch.Size([5, 600])\n",
            "[06] [     Out]: torch.Size([5, 300])\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# Hyper parameters\n",
        "D,L,T = 3,100,1000\n",
        "times = np.linspace(start=0.0,stop=1.0,num=100).reshape((-1,1)) # [L x 1]\n",
        "Gammas_np = np.zeros(shape=(D,L,L))\n",
        "hyp_lens = [1,0.1,0.01]\n",
        "for d_idx in range(D):\n",
        "    hyp_len = hyp_lens[d_idx]\n",
        "    Gammas_np[d_idx,:,:] = get_gamma(times=times,hyp_len=hyp_len,reg_coef=1e-6) # [L x L]\n",
        "Gammas = np2torch(Gammas_np) # [D x L x L]\n",
        "# Instantiate denoising dense U-net class\n",
        "model = DenoisingDenseUnetClass(\n",
        "    L=L,D=D,T=T,pos_emb_dim=16,h_dims=[64],z_dim=32,USE_POS_EMB=True,Gammas=Gammas)\n",
        "# Forward path\n",
        "B = 5 # batch size\n",
        "x = torch.randn(B,D*L) # [B x LD]\n",
        "steps = torch.zeros(B).type(torch.long) # [B]\n",
        "out = model(x=x,t=steps) # [B x DL]\n",
        "# Print-out forward path\n",
        "for key_idx,key in enumerate(model.nets.keys()):\n",
        "    net = model.nets[key]\n",
        "    print (\"[%02d] [%8s]: %s\"%(key_idx,key,net.shape))\n",
        "print (\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757cd736",
      "metadata": {
        "id": "757cd736"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a22b7fac",
      "metadata": {
        "id": "a22b7fac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcba939b",
      "metadata": {
        "id": "dcba939b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78f54ab",
      "metadata": {
        "id": "e78f54ab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ddd589e",
      "metadata": {
        "id": "4ddd589e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c415a5e9",
      "metadata": {
        "id": "c415a5e9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}